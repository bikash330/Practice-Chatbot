from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from enum import Enum
from pydantic import BaseModel, Field
import google.generativeai as genai
import os
import re
from dotenv import load_dotenv

# Load environment variables for API keys
load_dotenv()

# Initialize Google Gemini LLM
llm = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.3)

genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Regex for email and phone validation
EMAIL_REGEX = r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"
PHONE_REGEX = r"^\+?\d{10,15}$"


class PersonalDetails(BaseModel):
    name: str = Field(
        ...,
        description="This is the full name of the user",
    )
    email: str = Field(
        ...,
        description="This is the email of the user",
    )
    phone: str = Field(
        ...,
        description="This is the phone number of the user",
    )


llm = llm.with_structured_output(PersonalDetails)


user_details = PersonalDetails(name="", email="", phone="")


def check_what_is_empty(user_details):
    ask_for = []
    for field, value in user_details.dict().items():
        if value in [None, "", 0]:
            ask_for.append(field)
    return ask_for


# Function to validate email using regex
def is_valid_email(email):
    return re.match(EMAIL_REGEX, email) is not None


# Function to validate phone number using regex
def is_valid_phone(phone):
    return re.match(PHONE_REGEX, phone) is not None


# Function to generate a conversational query using the LLM
def ask_llm_for_field(field_name):
    # Prompt the LLM for conversational prompt generation
    prompt = f"A user has not provided their {field_name}. Ask them for this information politely."

    try:
        # Use the LLM to generate a natural question
        response = llm.invoke(prompt)
        print(response)

        # Check if the response is valid
        if response and hasattr(response, "generations") and response.generations:
            return response.text
        else:
            # If no valid response, return a fallback question
            print("LLM response was invalid, using fallback.")
            return f"Please provide your {field_name}:"

    except Exception as e:
        # Catch any other errors
        print(f"An error occurred: {e}")
        return f"Please provide your {field_name}:"


# Function to ask for missing fields in a conversational manner using the LLM
def ask_for_missing_fields_with_llm(user_details):
    ask_for = check_what_is_empty(user_details)

    while ask_for:  # Loop until all fields are filled
        for field in ask_for:
            while True:  # Keep asking until valid input is provided
                # Generate the LLM question for the missing field
                llm_question = ask_llm_for_field(field)
                print(llm_question)  # Print the question generated by the LLM

                user_input = input(f"{llm_question}: ")  # Get user input

                # Validate email and phone if necessary
                if field == "email" and not is_valid_email(user_input):
                    print("Invalid email format. Please try again.")
                    continue  # Ask again until a valid email is provided

                if field == "phone" and not is_valid_phone(user_input):
                    print("Invalid phone number format. Please try again.")
                    continue  # Ask again until a valid phone number is provided

                # Update the field with valid user input
                setattr(user_details, field, user_input)
                break  # Break the loop after valid input

        # Re-check which fields are still empty
        ask_for = check_what_is_empty(user_details)

    return user_details


# Start the conversation and ask for missing fields using LLM
updated_user_details = ask_for_missing_fields_with_llm(user_details)

print("\nThank you! Here are the details you provided:")
print(updated_user_details)
